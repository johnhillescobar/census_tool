# Fix Geography Validation & Agent Fallback Logic

## Problem Summary

The geography validator returns empty sets, causing all table validations to fail. The agent loops forever trying to validate, never proceeding to actual API calls. Tests only use mocks, so the real failure was never caught.

## Implementation Steps

### 1. Skip Validation Tool Entirely (Question 1: Option A)

**File**: `src/utils/agents/census_query_agent.py`

Remove `TableValidationTool` from the agent's tool list:

```python
# Line 67-77: Remove TableValidationTool from tools list
self.tools = [
    GeographyDiscoveryTool(),
    TableSearchTool(),
    CensusAPITool(),
    TableTool(),
    # TableValidationTool(),  # REMOVED - validation happens at API level
    PatternBuilderTool(),
    AreaResolutionTool(),
    ChartTool(),
    GeographyHierarchyTool(),
    VariableValidationTool(),
]
```

**Rationale**: The Census API itself validates geography support and returns clear 400 errors. Let the API be the source of truth instead of maintaining a fragile HTML scraper.

---

### 2. Update Agent Prompt to Remove Validation Step

**File**: `src/llm/config.py`

Update the CRITICAL REASONING CHECKLIST (around line 227-232):

```python
CRITICAL REASONING CHECKLIST (apply every time):
1. Determine user intent and target geography.
2. Use geography_discovery / resolve_area_name to gather parent context.
3. Call geography_hierarchy before pattern_builder to confirm parent ordering for complex geographies (CBSA, metro division, NECTA, etc.).
4. Run variable_validation immediately before pattern_builder or census_api_call; do not continue until all variables are valid or replaced.
5. After building the URL, execute census_api_call. If you get a 400 error about unsupported geography, try a different dataset or geography level.
6. On errors, inspect the message, adjust parameters (tokens, parents, variables), and retry with a different approach.
```

Remove all references to `validate_table_geography` tool from the prompt.

---

### 3. Add Agent Retry Limit with Clear Error Message (Question 2: Option B)

**File**: `src/utils/agents/census_query_agent.py`

Modify the `_parse_solution` method to detect iteration limits and return a clear error:

```python
# Around line 115-125
def _parse_solution(self, result: Dict) -> Dict:
    """Parse agent output - extract JSON after 'Final Answer:' prefix."""
    output = result.get("output", "")
    
    # Check if agent hit iteration/time limit
    if self._did_reach_iteration_limit(result, output):
        return self._build_iteration_limit_response(result, output)
    
    # ... rest of existing parsing logic
```

Add helper method:

```python
def _did_reach_iteration_limit(self, result: Dict, output: str) -> bool:
    """Check if agent exhausted iterations or time without completing."""
    intermediate_steps = result.get("intermediate_steps", [])
    
    # Hit max_iterations (30) or max_execution_time (180s)
    if len(intermediate_steps) >= 28:  # Close to limit
        return True
    
    # Check for repetitive tool calls (stuck in loop)
    if len(intermediate_steps) >= 10:
        recent_tools = [step[0].tool for step in intermediate_steps[-10:]]
        # If same tool called 5+ times in last 10 steps, likely stuck
        if any(recent_tools.count(tool) >= 5 for tool in set(recent_tools)):
            return True
    
    return False

def _build_iteration_limit_response(self, result: Dict, output: str) -> Dict:
    """Build error response when agent gets stuck."""
    intermediate_steps = result.get("intermediate_steps", [])
    recent_actions = [
        f"{step[0].tool}({step[0].tool_input[:50]}...)" 
        for step in intermediate_steps[-5:]
    ]
    
    return {
        "census_data": {"success": False, "data": []},
        "data_summary": "Agent exceeded iteration limit",
        "reasoning_trace": f"Agent made {len(intermediate_steps)} attempts. Recent: {recent_actions}",
        "answer_text": "I was unable to complete this query due to repeated validation failures. The Census API may not support this specific combination of table, geography, and year. Please try rephrasing your question or requesting a different geography level (e.g., state instead of county).",
        "charts_needed": [],
        "tables_needed": [],
        "footnotes": [
            "This query exceeded the maximum number of processing attempts.",
            "Try simplifying your request or using a more common geography level."
        ]
    }
```

---

### 4. Add Integration Tests with Real Census API (Question 3: Option C)

**New File**: `app_test_scripts/test_geography_validator_integration.py`

```python
"""
Integration tests that hit real Census API endpoints.
These are slower but catch real-world failures.
"""
import pytest
from src.utils.dataset_geography_validator import fetch_dataset_geography_levels, geography_supported


@pytest.mark.integration
def test_fetch_real_geography_levels_acs5_2023():
    """Test against actual Census API - ACS 5-Year 2023"""
    levels = fetch_dataset_geography_levels("acs/acs5", 2023, force_refresh=True)
    
    # Should find common levels
    assert "state" in levels or len(levels) == 0, "Either parser works or returns empty (expected current behavior)"
    
    # Document current state
    if len(levels) == 0:
        pytest.skip("Geography parser currently broken - returns empty set")


@pytest.mark.integration
def test_geography_supported_real_api():
    """Test validation against real API"""
    result = geography_supported("acs/acs5", 2023, "state")
    
    # Document what actually happens
    assert isinstance(result, dict)
    assert "supported" in result
    
    # Current behavior: returns False due to broken parser
    # Expected behavior: should return True for state level
    if not result["supported"]:
        pytest.skip("Validator broken - skipping validation and using API directly")
```

**New File**: `app_test_scripts/test_agent_fallback.py`

```python
"""
Test that agent doesn't loop forever when validation fails.
"""
from src.utils.agents.census_query_agent import CensusQueryAgent


def test_agent_returns_error_on_iteration_limit():
    """Agent should return clear error instead of looping forever"""
    agent = CensusQueryAgent()
    
    # Simulate a query that would cause validation loop
    # (This will be a real test once we implement the fallback)
    result = agent.solve(
        "What's the population of Mars?",  # Invalid geography
        {"is_census": True, "topic": "general"}
    )
    
    # Should get error response, not loop forever
    assert result["census_data"]["success"] is False
    assert "unable to complete" in result["answer_text"].lower() or "not available" in result["answer_text"].lower()
```

---

### 5. Keep Existing Mocked Tests for Fast CI

**No changes needed** - existing tests in `app_test_scripts/test_dataset_geography_validator.py` remain as fast unit tests.

Add pytest markers to separate test types:

**File**: `pytest.ini` (create if doesn't exist)

```ini
[pytest]
markers =
    integration: marks tests that hit real external APIs (slow)
    unit: marks fast unit tests with mocks (fast)
```

Run fast tests: `pytest -m "not integration"`

Run all tests: `pytest`

---

### 6. Update Test Suite to Handle Agent Errors Gracefully

**File**: `test_all_questions.py`

Update `run_single_question` to detect and log agent iteration limits:

```python
# Around line 54-62
result = graph.invoke(initial_state, config)

# Extract results
final = result.get("final", {})
answer = final.get("answer_text", "No answer")
generated_files = final.get("generated_files", [])
error = result.get("error")

# Check if agent hit iteration limit
if "exceeded iteration limit" in answer.lower() or "unable to complete" in answer.lower():
    logging.warning(f"Question {question_no} hit agent iteration limit")
    error = "Agent iteration limit exceeded"

success = bool(answer and answer != "No answer" and not error)
```

---

### 7. Add Manual QA Checklist

**New File**: `app_description/QA_CHECKLIST.md`

```markdown
# Manual QA Checklist - Geography Validation

Run these queries through main.py before declaring validation "fixed":

## Basic Queries (Should Work)
- [ ] "What's the population of California?" (state level)
- [ ] "Show population for all states" (state enumeration)
- [ ] "Population of Los Angeles County" (county level)

## Complex Queries (May Fail - Document Behavior)
- [ ] "Population by metropolitan division" (complex hierarchy)
- [ ] "Show data for CBSA 35620" (CBSA level)

## Expected Failures (Should Return Clear Error)
- [ ] "Population of Mars" (invalid geography)
- [ ] "Show me data from 1800" (invalid year)

## Validation
For each query:
1. Run: `python main.py`
2. Enter query
3. Check logs for:
   - Does it complete within 3 minutes? (Y/N)
   - Does it return an answer or clear error? (Y/N)
   - Does it loop with repeated tool calls? (Y/N - should be N)

Status: ðŸ”´ Fails / ðŸŸ¡ Works with caveats / ðŸŸ¢ Passes
```

---

## Testing Strategy

1. **Unit tests (fast)**: Keep existing mocked tests for CI
2. **Integration tests (slow)**: Add real API tests, mark with `@pytest.mark.integration`
3. **Manual QA**: Run checklist before each release
4. **End-to-end validation**: Run full 70-question suite, expect clear errors for unsupported queries

## Success Criteria

- [ ] Agent completes or returns clear error within 3 minutes for all 70 test questions
- [ ] No infinite loops (check logs for repeated tool calls)
- [ ] Integration tests document current validator behavior (even if broken)
- [ ] Manual QA checklist shows which queries work vs fail clearly

## Rollback Plan

If removing validation causes more problems:

1. Revert `census_query_agent.py` tool list
2. Revert `config.py` prompt changes
3. Keep the agent fallback logic (it helps regardless)