{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "361ada95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from future import annotations\n",
    "\n",
    "import os\n",
    "from typing import Annotated, List, Optional, TypedDict, Dict, Any\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed45936f",
   "metadata": {},
   "source": [
    "### Web search tool using DuckDuckGo (no API key needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f716a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ddgs import DDGS\n",
    "\n",
    "@tool\n",
    "def web_search(query: str, max_results: int = 5) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Search the web for the query and return a list of results with title, href, and body.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    with DDGS() as ddgs:\n",
    "        for r in ddgs.text(query, max_results=max_results):\n",
    "            results.append({\n",
    "            \"title\": r.get(\"title\"),\n",
    "            \"href\": r.get(\"href\"),\n",
    "            \"snippet\": r.get(\"body\")\n",
    "            })\n",
    "    return results\n",
    "\n",
    "@tool\n",
    "def calculator(expression: str) -> str:\n",
    "    \"\"\"\n",
    "    Safely evaluate a basic arithmetic expression.\n",
    "    Allowed characters: digits, +, -, , /, %, **, parentheses, space, decimal point.\n",
    "    \"\"\"\n",
    "\n",
    "    if not re.fullmatch(r\"[0-9.+-*/%()\\s*]\", expression):\n",
    "        raise ValueError(\"Disallowed characters in expression\")\n",
    "    # Evaluate in a restricted namespace\n",
    "    try:\n",
    "        result = eval(expression, {\"builtins\": {}}, {})\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error evaluating expression: {e}\"\n",
    "    return str(result)\n",
    "\n",
    "TOOLS = [web_search, calculator]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33488f3b",
   "metadata": {},
   "source": [
    "### ---------- Planning (structured output) ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07ca0411",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Plan(BaseModel):\n",
    "    objectives: List[str] = Field(default_factory=list, description=\"High-level goals to accomplish\")\n",
    "    steps: List[str] = Field(default_factory=list, description=\"Ordered, concrete steps to complete the task\")\n",
    "    assumptions: List[str] = Field(default_factory=list, description=\"Assumptions or constraints discovered\")\n",
    "    clarifying_questions: List[str] = Field(default_factory=list, description=\"Questions to ask the user if needed\")\n",
    "    success_criteria: List[str] = Field(default_factory=list, description=\"How to know the task is done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a94613",
   "metadata": {},
   "source": [
    "### ---------- State ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bcd77ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    # Conversation and intermediate context\n",
    "    messages: Annotated[List, add_messages]\n",
    "    # Structured plan from the planner\n",
    "    plan: Optional[Plan]\n",
    "    # Which step index we are on (0-based)\n",
    "    step_index: int\n",
    "    # Collected outputs from each step\n",
    "    results: List[Dict[str, Any]]\n",
    "    # Final answer to return to the user\n",
    "    final_answer: Optional[str]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57145a2",
   "metadata": {},
   "source": [
    "### ---------- Models ----------\n",
    "### You can swap models as preferred. Needs a model that supports tool-calling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b1ce659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed analyze_and_plan function\n",
    "def analyze_and_plan(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Analyze the user's ask and produce a Plan (objectives, steps, assumptions, etc.).\n",
    "    \"\"\"\n",
    "    # Get the latest user message\n",
    "    user_messages = [m for m in state[\"messages\"] if isinstance(m, HumanMessage)]\n",
    "    if not user_messages:\n",
    "        raise ValueError(\"No user messages found in state\")\n",
    "    user_msg = user_messages[-1]\n",
    "\n",
    "    plan: Plan = planner_llm.invoke([\n",
    "        PLANNER_SYSTEM,\n",
    "        HumanMessage(content=f\"User task:\\n{user_msg.content}\\n\\nReturn a plan.\")\n",
    "    ])\n",
    "\n",
    "    # Optional: Present a sanitized plan summary to the conversation context\n",
    "    plan_summary = \"Proposed plan:\\n\"\n",
    "    if plan.objectives:\n",
    "        plan_summary += \"- Objectives: \" + \"; \".join(plan.objectives) + \"\\n\"\n",
    "    if plan.steps:\n",
    "        plan_summary += \"- Steps:\\n\" + \"\\n\".join([f\"  {i+1}. {s}\" for i, s in enumerate(plan.steps)])\n",
    "    if plan.clarifying_questions:\n",
    "        plan_summary += \"\\n- Clarifying questions: \" + \"; \".join(plan.clarifying_questions)\n",
    "\n",
    "    return {\n",
    "        \"plan\": plan,\n",
    "        \"messages\": [AIMessage(content=plan_summary)],\n",
    "        \"step_index\": 0\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53b2a4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_MODEL = os.environ.get(\"AGENT_MODEL\", \"gpt-4o-mini\")\n",
    "\n",
    "llm = ChatOpenAI(model=DEFAULT_MODEL, temperature=0)\n",
    "planner_llm = llm.with_structured_output(Plan)  # For structured planning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfccc8d9",
   "metadata": {},
   "source": [
    "### ---------- System messages ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac9d2dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "PLANNER_SYSTEM = SystemMessage(content=(\n",
    "                                        \"You are a careful planner. Your job is to analyze the user's request and propose a clear, \"\n",
    "                                        \"feasible plan before any execution. Think through the task internally, but only return a concise plan, \"\n",
    "                                        \"not your private chain-of-thought. If you need clarifications, include them in clarifying_questions. \"\n",
    "                                        \"Focus on relevant steps that can be executed with available tools or reasoning.\"\n",
    "                                        ))\n",
    "\n",
    "EXECUTOR_SYSTEM = SystemMessage(content=(\n",
    "                                        \"You are a precise executor. Follow the provided plan step-by-step. For each step:\\n\"\n",
    "                                        \"- Either call a tool if needed (e.g., web_search, calculator), or produce a short step result.\\n\"\n",
    "                                        \"- Keep responses concise. Do not reveal private reasoning or chain-of-thought.\\n\"\n",
    "                                        \"- Do not produce the final answer here; only complete the current step.\\n\"\n",
    "                                        \"If you need more context, state what you need succinctly.\"\n",
    "                                        ))\n",
    "\n",
    "REFLECTOR_SYSTEM = SystemMessage(content=(\n",
    "                                        \"You are a careful summarizer. Given the plan, steps taken, and results, produce the final answer.\\n\"\n",
    "                                        \"Do not reveal private chain-of-thought. Provide a clear, complete result suitable for the user.\"\n",
    "                                        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be16fe6",
   "metadata": {},
   "source": [
    "### ---------- Nodes ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b82cf765",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_and_plan(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Analyze the user's ask and produce a Plan (objectives, steps, assumptions, etc.).\n",
    "    \"\"\"\n",
    "    # Get the latest user message\n",
    "    user_messages = [m for m in state[\"messages\"] if isinstance(m, HumanMessage)]\n",
    "    if not user_messages:\n",
    "        user_msg = user_messages[-1]\n",
    "\n",
    "    plan: Plan = planner_llm.invoke([\n",
    "        PLANNER_SYSTEM,\n",
    "        HumanMessage(content=f\"User task:\\n{user_msg.content}\\n\\nReturn a plan.\")\n",
    "    ])\n",
    "\n",
    "    # Optional: Present a sanitized plan summary to the conversation context\n",
    "    plan_summary = \"Proposed plan:\\n\"\n",
    "    if plan.objectives:\n",
    "        plan_summary += \"- Objectives: \" + \"; \".join(plan.objectives) + \"\\n\"\n",
    "    if plan.steps:\n",
    "        plan_summary += \"- Steps:\\n\" + \"\\n\".join([f\"  {i+1}. {s}\" for i, s in enumerate(plan.steps)])\n",
    "    if plan.clarifying_questions:\n",
    "        plan_summary += \"\\n- Clarifying questions: \" + \"; \".join(plan.clarifying_questions)\n",
    "\n",
    "    return {\n",
    "        \"plan\": plan,\n",
    "        \"messages\": [AIMessage(content=plan_summary)],\n",
    "        \"step_index\": 0\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e993bcdb",
   "metadata": {},
   "source": [
    "### Bind tools to the executor LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9018f242",
   "metadata": {},
   "outputs": [],
   "source": [
    "executor_llm = llm.bind_tools(TOOLS)\n",
    "\n",
    "def act_on_current_step(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Execute the current step: the model may either call a tool or provide a short step result.\n",
    "    \"\"\"\n",
    "    plan = state.get(\"plan\")\n",
    "    if not plan or not plan.steps:\n",
    "        # If no steps, fall back to simple answer\n",
    "        return {\"messages\": [AIMessage(content=\"No steps available. I will answer directly.\")]}\n",
    "    i = state.get(\"step_index\", 0)\n",
    "    steps = plan.steps\n",
    "    n = len(steps)\n",
    "    if i >= n:\n",
    "        # Already done\n",
    "        return {}\n",
    "\n",
    "    current_step = steps[i]\n",
    "    # Give the model just enough context\n",
    "    msgs = [\n",
    "        EXECUTOR_SYSTEM,\n",
    "        AIMessage(content=f\"Plan steps ({n} total):\\n\" + \"\\n\".join([f\"{idx+1}. {s}\" for idx, s in enumerate(steps)])),\n",
    "        AIMessage(content=f\"Current step {i+1}/{n}: {current_step}\"),\n",
    "    ]\n",
    "    # Include last few messages from the state, if helpful\n",
    "    # This keeps the context tighter to avoid accidental long history\n",
    "    msgs += state[\"messages\"][-6:]\n",
    "    response = executor_llm.invoke(msgs)\n",
    "    # The response (AIMessage) could include tool calls; ToolNode will handle them if present.\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "def advance_or_loop(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    If the last assistant message didn't call a tool, consider the step complete and advance.\n",
    "    Append the step result to state['results'].\n",
    "    \"\"\"\n",
    "    plan = state.get(\"plan\")\n",
    "    if not plan or not plan.steps:\n",
    "        return {}\n",
    "    i = state.get(\"step_index\", 0)\n",
    "    steps = plan.steps\n",
    "    if i >= len(steps):\n",
    "        return {}\n",
    "\n",
    "    # Find the last AI message content (not a tool message)\n",
    "    last_ai_msgs = [m for m in state[\"messages\"][::-1] if isinstance(m, AIMessage)]\n",
    "    if not last_ai_msgs:\n",
    "        return {}\n",
    "    last_ai = last_ai_msgs[0]\n",
    "\n",
    "    # Record the step output\n",
    "    step_record = {\n",
    "        \"step_number\": i + 1,\n",
    "        \"step_description\": steps[i],\n",
    "        \"output\": last_ai.content\n",
    "    }\n",
    "\n",
    "    new_results = list(state.get(\"results\", []))\n",
    "    new_results.append(step_record)\n",
    "\n",
    "    return {\n",
    "        \"results\": new_results,\n",
    "        \"step_index\": i + 1\n",
    "    }\n",
    "\n",
    "\n",
    "def reflect_and_finalize(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Summarize the entire work: plan, steps taken, and their outputs, then produce the final answer.\n",
    "    \"\"\"\n",
    "    plan = state.get(\"plan\")\n",
    "    results = state.get(\"results\", [])\n",
    "\n",
    "    plan_text = \"\"\n",
    "    if plan:\n",
    "        plan_text += \"Objectives: \" + \"; \".join(plan.objectives or []) + \"\\n\"\n",
    "        plan_text += \"Steps:\\n\" + \"\\n\".join([f\"{i+1}. {s}\" for i, s in enumerate(plan.steps or [])])\n",
    "\n",
    "    results_text = \"\"\n",
    "    if results:\n",
    "        results_text = \"\\nStep results:\\n\" + \"\\n\".join(\n",
    "            [f\"{r['step_number']}. {r['step_description']} -> {r['output']}\" for r in results]\n",
    "        )\n",
    "\n",
    "    msgs = [\n",
    "        REFLECTOR_SYSTEM,\n",
    "        AIMessage(content=\"Plan:\\n\" + plan_text),\n",
    "        AIMessage(content=results_text),\n",
    "        # Include the original user prompt for context\n",
    "    ]\n",
    "\n",
    "    # Add the last user message\n",
    "    user_messages = [m for m in state[\"messages\"] if isinstance(m, HumanMessage)]\n",
    "    if user_messages:\n",
    "        msgs.append(HumanMessage(content=\"Original user task:\\n\" + user_messages[-1].content))\n",
    "\n",
    "    final_resp = llm.invoke(msgs)\n",
    "    return {\n",
    "        \"final_answer\": final_resp.content,\n",
    "        \"messages\": [AIMessage(content=final_resp.content)]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7784f8d",
   "metadata": {},
   "source": [
    "### ---------- Graph wiring ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0506d64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph() -> StateGraph:\n",
    "    workflow = StateGraph(AgentState)\n",
    "\n",
    "    # Nodes\n",
    "    workflow.add_node(\"plan\", analyze_and_plan)\n",
    "    workflow.add_node(\"act\", act_on_current_step)\n",
    "    workflow.add_node(\"advance\", advance_or_loop)\n",
    "    tool_node = ToolNode(TOOLS)\n",
    "    workflow.add_node(\"tools\", tool_node)\n",
    "    workflow.add_node(\"finalize\", reflect_and_finalize)\n",
    "\n",
    "    # Edges\n",
    "    workflow.add_edge(START, \"plan\")\n",
    "    workflow.add_edge(\"plan\", \"act\")\n",
    "\n",
    "    # After \"act\", either go to tools (if there are tool calls) or advance\n",
    "    workflow.add_conditional_edges(\n",
    "        \"act\",\n",
    "        tools_condition,  # inspects last AI message in state[\"messages\"]\n",
    "        {\n",
    "            \"tools\": \"tools\",\n",
    "            \"end\": \"advance\"\n",
    "        }\n",
    "    )\n",
    "    # After tools execute, loop back to \"act\" so the model can see tool results\n",
    "    workflow.add_edge(\"tools\", \"act\")\n",
    "\n",
    "    # After \"advance\", either continue to next step or finalize\n",
    "    def should_continue(state: AgentState) -> str:\n",
    "        plan = state.get(\"plan\")\n",
    "        i = state.get(\"step_index\", 0)\n",
    "        if not plan or not plan.steps:\n",
    "            return \"finalize\"\n",
    "        if i < len(plan.steps):\n",
    "            return \"act\"\n",
    "        return \"finalize\"\n",
    "\n",
    "    workflow.add_conditional_edges(\"advance\", should_continue, {\"act\": \"act\", \"finalize\": \"finalize\"})\n",
    "    workflow.add_edge(\"finalize\", END)\n",
    "\n",
    "    return workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5379ec7e",
   "metadata": {},
   "source": [
    "### ---------- Run ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d962e2b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'user_msg' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnboundLocalError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# Invoke the graph with thread configuration for the checkpointer\u001b[39;00m\n\u001b[32m     24\u001b[39m config = {\u001b[33m\"\u001b[39m\u001b[33mconfigurable\u001b[39m\u001b[33m\"\u001b[39m: {\u001b[33m\"\u001b[39m\u001b[33mthread_id\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mdemo-thread-1\u001b[39m\u001b[33m\"\u001b[39m}}\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m result = \u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# Print outputs\u001b[39;00m\n\u001b[32m     28\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Plan ---\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johnh\\Dropbox\\Python\\census_tool\\.venv\\Lib\\site-packages\\langgraph\\pregel\\main.py:3026\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3023\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3024\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3026\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3027\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3028\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3029\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3030\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3031\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3032\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3033\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3034\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3035\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3036\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3037\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3038\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3039\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3040\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3041\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johnh\\Dropbox\\Python\\census_tool\\.venv\\Lib\\site-packages\\langgraph\\pregel\\main.py:2647\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2645\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2646\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2647\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2648\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2649\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2650\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2651\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2652\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2653\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2654\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2656\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2657\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johnh\\Dropbox\\Python\\census_tool\\.venv\\Lib\\site-packages\\langgraph\\pregel\\_runner.py:162\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    160\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johnh\\Dropbox\\Python\\census_tool\\.venv\\Lib\\site-packages\\langgraph\\pregel\\_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johnh\\Dropbox\\Python\\census_tool\\.venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:657\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    655\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    656\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m657\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    659\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johnh\\Dropbox\\Python\\census_tool\\.venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:401\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    399\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    400\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    403\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36manalyze_and_plan\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m user_messages:\n\u001b[32m      8\u001b[39m     user_msg = user_messages[-\u001b[32m1\u001b[39m]\n\u001b[32m     10\u001b[39m plan: Plan = planner_llm.invoke([\n\u001b[32m     11\u001b[39m     PLANNER_SYSTEM,\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     HumanMessage(content=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUser task:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43muser_msg\u001b[49m.content\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mReturn a plan.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m ])\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Optional: Present a sanitized plan summary to the conversation context\u001b[39;00m\n\u001b[32m     16\u001b[39m plan_summary = \u001b[33m\"\u001b[39m\u001b[33mProposed plan:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mUnboundLocalError\u001b[39m: cannot access local variable 'user_msg' where it is not associated with a value",
      "During task with name 'plan' and id '33a1e22b-9655-b3ba-448e-2549a01d9e0d'"
     ]
    }
   ],
   "source": [
    "# if name == \"main\":\n",
    "# Build and compile graph with in-memory checkpointing (optional)\n",
    "memory = MemorySaver()\n",
    "graph = create_graph().compile(checkpointer=memory)\n",
    "\n",
    "# Example task:\n",
    "# - The agent will plan first, then execute steps with tools as needed.\n",
    "user_task = input(\"Enter your task:\\n> \").strip()\n",
    "initial_state: AgentState = {\n",
    "    \"messages\": [\n",
    "        SystemMessage(content=(\n",
    "            \"You are a helpful assistant. Think step-by-step privately, \"\n",
    "            \"but only share a short plan and the final results. Do not reveal your chain-of-thought.\"\n",
    "        )),\n",
    "        HumanMessage(content=user_task),\n",
    "    ],\n",
    "    \"plan\": None,\n",
    "    \"step_index\": 0,\n",
    "    \"results\": [],\n",
    "    \"final_answer\": None\n",
    "}\n",
    "\n",
    "# Invoke the graph with thread configuration for the checkpointer\n",
    "config = {\"configurable\": {\"thread_id\": \"demo-thread-1\"}}\n",
    "result = graph.invoke(initial_state, config)\n",
    "\n",
    "# Print outputs\n",
    "print(\"\\n--- Plan ---\")\n",
    "if result.get(\"plan\"):\n",
    "    plan = result[\"plan\"]\n",
    "    print(\"Objectives:\", \"; \".join(plan.objectives or []))\n",
    "    print(\"Steps:\")\n",
    "    for idx, s in enumerate(plan.steps or []):\n",
    "        print(f\"  {idx+1}. {s}\")\n",
    "    if plan.clarifying_questions:\n",
    "        print(\"Clarifying questions:\", \"; \".join(plan.clarifying_questions))\n",
    "    if plan.assumptions:\n",
    "        print(\"Assumptions:\", \"; \".join(plan.assumptions))\n",
    "    if plan.success_criteria:\n",
    "        print(\"Success criteria:\", \"; \".join(plan.success_criteria))\n",
    "\n",
    "print(\"\\n--- Step Results ---\")\n",
    "for r in result.get(\"results\", []):\n",
    "    print(f\"{r['step_number']}. {r['step_description']}\")\n",
    "    print(f\"   Output: {r['output']}\")\n",
    "\n",
    "print(\"\\n--- Final Answer ---\")\n",
    "print(result.get(\"final_answer\") or \"(No final answer produced)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e534faca",
   "metadata": {},
   "source": [
    "How it works\n",
    "\n",
    "* plan node: Produces a structured Plan (objectives, steps, assumptions, clarifying questions, success criteria) using structured output. Shares a short plan summary with the conversation context.\n",
    "* act node: Executes one step at a time. The model can call tools (web_search, calculator) or produce a short step result.\n",
    "* ToolNode: Runs any tool calls and appends their outputs to messages; then act runs again, allowing the model to use tool output.\n",
    "* advance node: If no tool call was made in act, we treat the step as completed, record its output, and advance to the next step.\n",
    "* finalize node: Reflects over plan + step results and produces a final answer.\n",
    "* Safety: The prompts instruct the model to reason privately and only share concise plan/outputs, never raw chain-of-thought.\n",
    "\n",
    "Customization ideas\n",
    "\n",
    "* Pause for plan approval: After plan, insert an interrupt or a human-in-the-loop gate to confirm or edit the plan before proceeding.\n",
    "* Add more tools: e.g., structured web APIs, database lookups, code execution sandboxes.\n",
    "* Memory and persistence: Use a real checkpointer (e.g., Postgres) if you need resumable runs.\n",
    "* Guardrails: Put limits on max cycles per step to avoid infinite loops; add routing based on step type to choose specific tool subsets.\n",
    "If you want, I can add an optional “plan approval” pause or convert this to a multi-agent pattern (planner/executor/critic) while keeping private reasoning hidden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63e01c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph compiled successfully with the fixed analyze_and_plan function!\n"
     ]
    }
   ],
   "source": [
    "# Re-create and compile the graph with the corrected function\n",
    "def create_graph_fixed() -> StateGraph:\n",
    "    workflow = StateGraph(AgentState)\n",
    "\n",
    "    # Nodes - using the corrected analyze_and_plan function from cell 8\n",
    "    workflow.add_node(\"plan\", analyze_and_plan)\n",
    "    workflow.add_node(\"act\", act_on_current_step)\n",
    "    workflow.add_node(\"advance\", advance_or_loop)\n",
    "    tool_node = ToolNode(TOOLS)\n",
    "    workflow.add_node(\"tools\", tool_node)\n",
    "    workflow.add_node(\"finalize\", reflect_and_finalize)\n",
    "\n",
    "    # Edges\n",
    "    workflow.add_edge(START, \"plan\")\n",
    "    workflow.add_edge(\"plan\", \"act\")\n",
    "\n",
    "    # After \"act\", either go to tools (if there are tool calls) or advance\n",
    "    workflow.add_conditional_edges(\n",
    "        \"act\",\n",
    "        tools_condition,  # inspects last AI message in state[\"messages\"]\n",
    "        {\n",
    "            \"tools\": \"tools\",\n",
    "            \"end\": \"advance\"\n",
    "        }\n",
    "    )\n",
    "    # After tools execute, loop back to \"act\" so the model can see tool results\n",
    "    workflow.add_edge(\"tools\", \"act\")\n",
    "\n",
    "    # After \"advance\", either continue to next step or finalize\n",
    "    def should_continue(state: AgentState) -> str:\n",
    "        plan = state.get(\"plan\")\n",
    "        i = state.get(\"step_index\", 0)\n",
    "        if not plan or not plan.steps:\n",
    "            return \"finalize\"\n",
    "        if i < len(plan.steps):\n",
    "            return \"act\"\n",
    "        return \"finalize\"\n",
    "\n",
    "    workflow.add_conditional_edges(\"advance\", should_continue, {\"act\": \"act\", \"finalize\": \"finalize\"})\n",
    "    workflow.add_edge(\"finalize\", END)\n",
    "\n",
    "    return workflow\n",
    "\n",
    "# Build and compile graph with in-memory checkpointing using the fixed function\n",
    "memory = MemorySaver()\n",
    "graph_fixed = create_graph_fixed().compile(checkpointer=memory)\n",
    "\n",
    "print(\"Graph compiled successfully with the fixed analyze_and_plan function!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40135f82",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'user_msg' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnboundLocalError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Invoke the FIXED graph with thread configuration for the checkpointer\u001b[39;00m\n\u001b[32m     18\u001b[39m config = {\u001b[33m\"\u001b[39m\u001b[33mconfigurable\u001b[39m\u001b[33m\"\u001b[39m: {\u001b[33m\"\u001b[39m\u001b[33mthread_id\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mdemo-thread-1\u001b[39m\u001b[33m\"\u001b[39m}}\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m result = \u001b[43mgraph_fixed\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Print outputs\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Plan ---\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johnh\\Dropbox\\Python\\census_tool\\.venv\\Lib\\site-packages\\langgraph\\pregel\\main.py:3026\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3023\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3024\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3026\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3027\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3028\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3029\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3030\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3031\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3032\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3033\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3034\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3035\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3036\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3037\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3038\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3039\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3040\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3041\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johnh\\Dropbox\\Python\\census_tool\\.venv\\Lib\\site-packages\\langgraph\\pregel\\main.py:2647\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2645\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2646\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2647\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2648\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2649\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2650\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2651\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2652\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2653\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2654\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2656\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2657\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johnh\\Dropbox\\Python\\census_tool\\.venv\\Lib\\site-packages\\langgraph\\pregel\\_runner.py:162\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    160\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johnh\\Dropbox\\Python\\census_tool\\.venv\\Lib\\site-packages\\langgraph\\pregel\\_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johnh\\Dropbox\\Python\\census_tool\\.venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:657\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    655\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    656\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m657\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    659\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johnh\\Dropbox\\Python\\census_tool\\.venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:401\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    399\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    400\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    403\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36manalyze_and_plan\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m user_messages:\n\u001b[32m      8\u001b[39m     user_msg = user_messages[-\u001b[32m1\u001b[39m]\n\u001b[32m     10\u001b[39m plan: Plan = planner_llm.invoke([\n\u001b[32m     11\u001b[39m     PLANNER_SYSTEM,\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     HumanMessage(content=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUser task:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43muser_msg\u001b[49m.content\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mReturn a plan.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m ])\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Optional: Present a sanitized plan summary to the conversation context\u001b[39;00m\n\u001b[32m     16\u001b[39m plan_summary = \u001b[33m\"\u001b[39m\u001b[33mProposed plan:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mUnboundLocalError\u001b[39m: cannot access local variable 'user_msg' where it is not associated with a value",
      "During task with name 'plan' and id '8629e1dc-f6ec-4bbc-6fcb-268ad69e305f'"
     ]
    }
   ],
   "source": [
    "# Test the fixed agent\n",
    "user_task = input(\"Enter your task:\\n> \").strip()\n",
    "initial_state: AgentState = {\n",
    "    \"messages\": [\n",
    "        SystemMessage(content=(\n",
    "            \"You are a helpful assistant. Think step-by-step privately, \"\n",
    "            \"but only share a short plan and the final results. Do not reveal your chain-of-thought.\"\n",
    "        )),\n",
    "        HumanMessage(content=user_task),\n",
    "    ],\n",
    "    \"plan\": None,\n",
    "    \"step_index\": 0,\n",
    "    \"results\": [],\n",
    "    \"final_answer\": None\n",
    "}\n",
    "\n",
    "# Invoke the FIXED graph with thread configuration for the checkpointer\n",
    "config = {\"configurable\": {\"thread_id\": \"demo-thread-1\"}}\n",
    "result = graph_fixed.invoke(initial_state, config)\n",
    "\n",
    "# Print outputs\n",
    "print(\"\\n--- Plan ---\")\n",
    "if result.get(\"plan\"):\n",
    "    plan = result[\"plan\"]\n",
    "    print(\"Objectives:\", \"; \".join(plan.objectives or []))\n",
    "    print(\"Steps:\")\n",
    "    for idx, s in enumerate(plan.steps or []):\n",
    "        print(f\"  {idx+1}. {s}\")\n",
    "    if plan.clarifying_questions:\n",
    "        print(\"Clarifying questions:\", \"; \".join(plan.clarifying_questions))\n",
    "    if plan.assumptions:\n",
    "        print(\"Assumptions:\", \"; \".join(plan.assumptions))\n",
    "    if plan.success_criteria:\n",
    "        print(\"Success criteria:\", \"; \".join(plan.success_criteria))\n",
    "\n",
    "print(\"\\n--- Step Results ---\")\n",
    "for r in result.get(\"results\", []):\n",
    "    print(f\"{r['step_number']}. {r['step_description']}\")\n",
    "    print(f\"   Output: {r['output']}\")\n",
    "\n",
    "print(\"\\n--- Final Answer ---\")\n",
    "print(result.get(\"final_answer\") or \"(No final answer produced)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92517163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with ACTUALLY FIXED analyze_and_plan function compiled successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create a completely new function with a different name to avoid confusion\n",
    "def analyze_and_plan_FIXED(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Analyze the user's ask and produce a Plan (objectives, steps, assumptions, etc.).\n",
    "    FIXED VERSION: Properly handles case when no user messages exist.\n",
    "    \"\"\"\n",
    "    # Get the latest user message\n",
    "    user_messages = [m for m in state[\"messages\"] if isinstance(m, HumanMessage)]\n",
    "    if not user_messages:\n",
    "        raise ValueError(\"No user messages found in state\")\n",
    "    user_msg = user_messages[-1]\n",
    "\n",
    "    plan: Plan = planner_llm.invoke([\n",
    "        PLANNER_SYSTEM,\n",
    "        HumanMessage(content=f\"User task:\\n{user_msg.content}\\n\\nReturn a plan.\")\n",
    "    ])\n",
    "\n",
    "    # Optional: Present a sanitized plan summary to the conversation context\n",
    "    plan_summary = \"Proposed plan:\\n\"\n",
    "    if plan.objectives:\n",
    "        plan_summary += \"- Objectives: \" + \"; \".join(plan.objectives) + \"\\n\"\n",
    "    if plan.steps:\n",
    "        plan_summary += \"- Steps:\\n\" + \"\\n\".join([f\"  {i+1}. {s}\" for i, s in enumerate(plan.steps)])\n",
    "    if plan.clarifying_questions:\n",
    "        plan_summary += \"\\n- Clarifying questions: \" + \"; \".join(plan.clarifying_questions)\n",
    "\n",
    "    return {\n",
    "        \"plan\": plan,\n",
    "        \"messages\": [AIMessage(content=plan_summary)],\n",
    "        \"step_index\": 0\n",
    "    }\n",
    "\n",
    "# Create the completely fixed graph using the new function name\n",
    "def create_graph_ACTUALLY_FIXED() -> StateGraph:\n",
    "    workflow = StateGraph(AgentState)\n",
    "\n",
    "    # Nodes - using the ACTUALLY FIXED function\n",
    "    workflow.add_node(\"plan\", analyze_and_plan_FIXED)  # <- Note: different function name\n",
    "    workflow.add_node(\"act\", act_on_current_step)\n",
    "    workflow.add_node(\"advance\", advance_or_loop)\n",
    "    tool_node = ToolNode(TOOLS)\n",
    "    workflow.add_node(\"tools\", tool_node)\n",
    "    workflow.add_node(\"finalize\", reflect_and_finalize)\n",
    "\n",
    "    # Edges\n",
    "    workflow.add_edge(START, \"plan\")\n",
    "    workflow.add_edge(\"plan\", \"act\")\n",
    "\n",
    "    # After \"act\", either go to tools (if there are tool calls) or advance\n",
    "    workflow.add_conditional_edges(\n",
    "        \"act\",\n",
    "        tools_condition,  # inspects last AI message in state[\"messages\"]\n",
    "        {\n",
    "            \"tools\": \"tools\",\n",
    "            \"end\": \"advance\"\n",
    "        }\n",
    "    )\n",
    "    # After tools execute, loop back to \"act\" so the model can see tool results\n",
    "    workflow.add_edge(\"tools\", \"act\")\n",
    "\n",
    "    # After \"advance\", either continue to next step or finalize\n",
    "    def should_continue(state: AgentState) -> str:\n",
    "        plan = state.get(\"plan\")\n",
    "        i = state.get(\"step_index\", 0)\n",
    "        if not plan or not plan.steps:\n",
    "            return \"finalize\"\n",
    "        if i < len(plan.steps):\n",
    "            return \"act\"\n",
    "        return \"finalize\"\n",
    "\n",
    "    workflow.add_conditional_edges(\"advance\", should_continue, {\"act\": \"act\", \"finalize\": \"finalize\"})\n",
    "    workflow.add_edge(\"finalize\", END)\n",
    "\n",
    "    return workflow\n",
    "\n",
    "# Build the ACTUALLY FIXED graph\n",
    "memory_fixed = MemorySaver()\n",
    "graph_ACTUALLY_FIXED = create_graph_ACTUALLY_FIXED().compile(checkpointer=memory_fixed)\n",
    "\n",
    "print(\"Graph with ACTUALLY FIXED analyze_and_plan function compiled successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5851a88c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johnh\\AppData\\Local\\Temp\\ipykernel_29180\\2650267151.py:9: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n",
      "C:\\Users\\johnh\\AppData\\Local\\Temp\\ipykernel_29180\\2650267151.py:9: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n",
      "C:\\Users\\johnh\\AppData\\Local\\Temp\\ipykernel_29180\\2650267151.py:9: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n",
      "C:\\Users\\johnh\\AppData\\Local\\Temp\\ipykernel_29180\\2650267151.py:9: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n",
      "C:\\Users\\johnh\\AppData\\Local\\Temp\\ipykernel_29180\\2650267151.py:9: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n",
      "C:\\Users\\johnh\\AppData\\Local\\Temp\\ipykernel_29180\\2650267151.py:9: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n",
      "C:\\Users\\johnh\\AppData\\Local\\Temp\\ipykernel_29180\\2650267151.py:9: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n",
      "C:\\Users\\johnh\\AppData\\Local\\Temp\\ipykernel_29180\\2650267151.py:9: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n",
      "C:\\Users\\johnh\\AppData\\Local\\Temp\\ipykernel_29180\\2650267151.py:9: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n",
      "C:\\Users\\johnh\\AppData\\Local\\Temp\\ipykernel_29180\\2650267151.py:9: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n",
      "C:\\Users\\johnh\\AppData\\Local\\Temp\\ipykernel_29180\\2650267151.py:9: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n",
      "C:\\Users\\johnh\\AppData\\Local\\Temp\\ipykernel_29180\\2650267151.py:9: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "ename": "GraphRecursionError",
     "evalue": "Recursion limit of 25 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/GRAPH_RECURSION_LIMIT",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mGraphRecursionError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Invoke the ACTUALLY FIXED graph \u001b[39;00m\n\u001b[32m     18\u001b[39m config = {\u001b[33m\"\u001b[39m\u001b[33mconfigurable\u001b[39m\u001b[33m\"\u001b[39m: {\u001b[33m\"\u001b[39m\u001b[33mthread_id\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mdemo-thread-2\u001b[39m\u001b[33m\"\u001b[39m}}\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m result = \u001b[43mgraph_ACTUALLY_FIXED\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Print outputs\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Plan ---\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johnh\\Dropbox\\Python\\census_tool\\.venv\\Lib\\site-packages\\langgraph\\pregel\\main.py:3026\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3023\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3024\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3026\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3027\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3028\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3029\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3030\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3031\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3032\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3033\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3034\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3035\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3036\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3037\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3038\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3039\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3040\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3041\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\johnh\\Dropbox\\Python\\census_tool\\.venv\\Lib\\site-packages\\langgraph\\pregel\\main.py:2675\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2666\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m loop.status == \u001b[33m\"\u001b[39m\u001b[33mout_of_steps\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   2667\u001b[39m     msg = create_error_message(\n\u001b[32m   2668\u001b[39m         message=(\n\u001b[32m   2669\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRecursion limit of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[33m'\u001b[39m\u001b[33mrecursion_limit\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m reached \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2673\u001b[39m         error_code=ErrorCode.GRAPH_RECURSION_LIMIT,\n\u001b[32m   2674\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m2675\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m GraphRecursionError(msg)\n\u001b[32m   2676\u001b[39m \u001b[38;5;66;03m# set final channel values as run output\u001b[39;00m\n\u001b[32m   2677\u001b[39m run_manager.on_chain_end(loop.output)\n",
      "\u001b[31mGraphRecursionError\u001b[39m: Recursion limit of 25 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/GRAPH_RECURSION_LIMIT"
     ]
    }
   ],
   "source": [
    "# Test the ACTUALLY FIXED agent\n",
    "user_task = input(\"Enter your task:\\n> \").strip()\n",
    "initial_state: AgentState = {\n",
    "    \"messages\": [\n",
    "        SystemMessage(content=(\n",
    "            \"You are a helpful assistant. Think step-by-step privately, \"\n",
    "            \"but only share a short plan and the final results. Do not reveal your chain-of-thought.\"\n",
    "        )),\n",
    "        HumanMessage(content=user_task),\n",
    "    ],\n",
    "    \"plan\": None,\n",
    "    \"step_index\": 0,\n",
    "    \"results\": [],\n",
    "    \"final_answer\": None\n",
    "}\n",
    "\n",
    "# Invoke the ACTUALLY FIXED graph \n",
    "config = {\"configurable\": {\"thread_id\": \"demo-thread-2\"}}\n",
    "result = graph_ACTUALLY_FIXED.invoke(initial_state, config)\n",
    "\n",
    "# Print outputs\n",
    "print(\"\\n--- Plan ---\")\n",
    "if result.get(\"plan\"):\n",
    "    plan = result[\"plan\"]\n",
    "    print(\"Objectives:\", \"; \".join(plan.objectives or []))\n",
    "    print(\"Steps:\")\n",
    "    for idx, s in enumerate(plan.steps or []):\n",
    "        print(f\"  {idx+1}. {s}\")\n",
    "    if plan.clarifying_questions:\n",
    "        print(\"Clarifying questions:\", \"; \".join(plan.clarifying_questions))\n",
    "    if plan.assumptions:\n",
    "        print(\"Assumptions:\", \"; \".join(plan.assumptions))\n",
    "    if plan.success_criteria:\n",
    "        print(\"Success criteria:\", \"; \".join(plan.success_criteria))\n",
    "\n",
    "print(\"\\n--- Step Results ---\")\n",
    "for r in result.get(\"results\", []):\n",
    "    print(f\"{r['step_number']}. {r['step_description']}\")\n",
    "    print(f\"   Output: {r['output']}\")\n",
    "\n",
    "print(\"\\n--- Final Answer ---\")\n",
    "print(result.get(\"final_answer\") or \"(No final answer produced)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1bee22c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG graph compiled successfully!\n"
     ]
    }
   ],
   "source": [
    "# Debug version with recursion limits and better logging\n",
    "def create_graph_DEBUG() -> StateGraph:\n",
    "    workflow = StateGraph(AgentState)\n",
    "\n",
    "    # Enhanced functions with debugging\n",
    "    def debug_should_continue(state: AgentState) -> str:\n",
    "        plan = state.get(\"plan\")\n",
    "        i = state.get(\"step_index\", 0)\n",
    "        print(f\"DEBUG should_continue: step_index={i}, plan exists={plan is not None}\")\n",
    "        if plan and plan.steps:\n",
    "            print(f\"DEBUG: Plan has {len(plan.steps)} steps\")\n",
    "            print(f\"DEBUG: Current step index: {i}\")\n",
    "        \n",
    "        if not plan or not plan.steps:\n",
    "            print(\"DEBUG: No plan or no steps, going to finalize\")\n",
    "            return \"finalize\"\n",
    "        if i < len(plan.steps):\n",
    "            print(f\"DEBUG: Step {i+1}/{len(plan.steps)}, continuing to act\")\n",
    "            return \"act\"\n",
    "        print(\"DEBUG: All steps completed, going to finalize\")\n",
    "        return \"finalize\"\n",
    "\n",
    "    def debug_advance_or_loop(state: AgentState) -> AgentState:\n",
    "        \"\"\"Enhanced advance function with debugging\"\"\"\n",
    "        plan = state.get(\"plan\")\n",
    "        if not plan or not plan.steps:\n",
    "            print(\"DEBUG advance: No plan or steps, returning empty\")\n",
    "            return {}\n",
    "        \n",
    "        i = state.get(\"step_index\", 0)\n",
    "        steps = plan.steps\n",
    "        print(f\"DEBUG advance: Current step {i}, total steps {len(steps)}\")\n",
    "        \n",
    "        if i >= len(steps):\n",
    "            print(\"DEBUG advance: Already at or past last step\")\n",
    "            return {}\n",
    "\n",
    "        # Find the last AI message content (not a tool message)\n",
    "        last_ai_msgs = [m for m in state[\"messages\"][::-1] if isinstance(m, AIMessage)]\n",
    "        if not last_ai_msgs:\n",
    "            print(\"DEBUG advance: No AI messages found\")\n",
    "            return {}\n",
    "        last_ai = last_ai_msgs[0]\n",
    "\n",
    "        # Record the step output\n",
    "        step_record = {\n",
    "            \"step_number\": i + 1,\n",
    "            \"step_description\": steps[i],\n",
    "            \"output\": last_ai.content[:100] + \"...\" if len(last_ai.content) > 100 else last_ai.content\n",
    "        }\n",
    "        print(f\"DEBUG advance: Recording step {i+1}: {step_record['step_description']}\")\n",
    "\n",
    "        new_results = list(state.get(\"results\", []))\n",
    "        new_results.append(step_record)\n",
    "\n",
    "        new_step_index = i + 1\n",
    "        print(f\"DEBUG advance: Advancing from step {i} to step {new_step_index}\")\n",
    "        \n",
    "        return {\n",
    "            \"results\": new_results,\n",
    "            \"step_index\": new_step_index\n",
    "        }\n",
    "\n",
    "    # Nodes - using the ACTUALLY FIXED function\n",
    "    workflow.add_node(\"plan\", analyze_and_plan_FIXED)\n",
    "    workflow.add_node(\"act\", act_on_current_step)\n",
    "    workflow.add_node(\"advance\", debug_advance_or_loop)  # Use debug version\n",
    "    tool_node = ToolNode(TOOLS)\n",
    "    workflow.add_node(\"tools\", tool_node)\n",
    "    workflow.add_node(\"finalize\", reflect_and_finalize)\n",
    "\n",
    "    # Edges\n",
    "    workflow.add_edge(START, \"plan\")\n",
    "    workflow.add_edge(\"plan\", \"act\")\n",
    "\n",
    "    # After \"act\", either go to tools (if there are tool calls) or advance\n",
    "    workflow.add_conditional_edges(\n",
    "        \"act\",\n",
    "        tools_condition,  # inspects last AI message in state[\"messages\"]\n",
    "        {\n",
    "            \"tools\": \"tools\",\n",
    "            \"end\": \"advance\"\n",
    "        }\n",
    "    )\n",
    "    # After tools execute, loop back to \"act\" so the model can see tool results\n",
    "    workflow.add_edge(\"tools\", \"act\")\n",
    "\n",
    "    # After \"advance\", either continue to next step or finalize\n",
    "    workflow.add_conditional_edges(\"advance\", debug_should_continue, {\"act\": \"act\", \"finalize\": \"finalize\"})\n",
    "    workflow.add_edge(\"finalize\", END)\n",
    "\n",
    "    return workflow\n",
    "\n",
    "# Build the DEBUG graph with increased recursion limit\n",
    "memory_debug = MemorySaver()\n",
    "graph_DEBUG = create_graph_DEBUG().compile(checkpointer=memory_debug)\n",
    "\n",
    "print(\"DEBUG graph compiled successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "143a840c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting DEBUG agent execution...\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johnh\\AppData\\Local\\Temp\\ipykernel_29180\\2650267151.py:9: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n",
      "C:\\Users\\johnh\\AppData\\Local\\Temp\\ipykernel_29180\\2650267151.py:9: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n",
      "C:\\Users\\johnh\\AppData\\Local\\Temp\\ipykernel_29180\\2650267151.py:9: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n",
      "C:\\Users\\johnh\\AppData\\Local\\Temp\\ipykernel_29180\\2650267151.py:9: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n",
      "C:\\Users\\johnh\\AppData\\Local\\Temp\\ipykernel_29180\\2650267151.py:9: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ERROR OCCURRED: Error code: 400 - {'error': {'message': \"Invalid parameter: messages with role 'tool' must be a response to a preceeding message with 'tool_calls'.\", 'type': 'invalid_request_error', 'param': 'messages.[3].role', 'code': None}}\n",
      "Check the debug output above to identify the issue.\n"
     ]
    }
   ],
   "source": [
    "# Test with DEBUG version and increased recursion limit\n",
    "user_task = input(\"Enter your task:\\n> \").strip()\n",
    "initial_state: AgentState = {\n",
    "    \"messages\": [\n",
    "        SystemMessage(content=(\n",
    "            \"You are a helpful assistant. Think step-by-step privately, \"\n",
    "            \"but only share a short plan and the final results. Do not reveal your chain-of-thought.\"\n",
    "        )),\n",
    "        HumanMessage(content=user_task),\n",
    "    ],\n",
    "    \"plan\": None,\n",
    "    \"step_index\": 0,\n",
    "    \"results\": [],\n",
    "    \"final_answer\": None\n",
    "}\n",
    "\n",
    "# Invoke with increased recursion limit and debugging\n",
    "config = {\n",
    "    \"configurable\": {\"thread_id\": \"debug-thread-1\"},\n",
    "    \"recursion_limit\": 50  # Increased from default 25\n",
    "}\n",
    "\n",
    "print(\"Starting DEBUG agent execution...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "    result = graph_DEBUG.invoke(initial_state, config)\n",
    "    \n",
    "    # Print outputs\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"DEBUG EXECUTION COMPLETED SUCCESSFULLY!\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    print(\"\\n--- Plan ---\")\n",
    "    if result.get(\"plan\"):\n",
    "        plan = result[\"plan\"]\n",
    "        print(\"Objectives:\", \"; \".join(plan.objectives or []))\n",
    "        print(\"Steps:\")\n",
    "        for idx, s in enumerate(plan.steps or []):\n",
    "            print(f\"  {idx+1}. {s}\")\n",
    "        if plan.clarifying_questions:\n",
    "            print(\"Clarifying questions:\", \"; \".join(plan.clarifying_questions))\n",
    "        if plan.assumptions:\n",
    "            print(\"Assumptions:\", \"; \".join(plan.assumptions))\n",
    "        if plan.success_criteria:\n",
    "            print(\"Success criteria:\", \"; \".join(plan.success_criteria))\n",
    "\n",
    "    print(\"\\n--- Step Results ---\")\n",
    "    for r in result.get(\"results\", []):\n",
    "        print(f\"{r['step_number']}. {r['step_description']}\")\n",
    "        print(f\"   Output: {r['output']}\")\n",
    "\n",
    "    print(\"\\n--- Final Answer ---\")\n",
    "    print(result.get(\"final_answer\") or \"(No final answer produced)\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nERROR OCCURRED: {e}\")\n",
    "    print(\"Check the debug output above to identify the issue.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec83cb7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIMPLE graph (no tools) compiled successfully!\n"
     ]
    }
   ],
   "source": [
    "# Simple version without tools to test basic flow\n",
    "def create_graph_SIMPLE() -> StateGraph:\n",
    "    workflow = StateGraph(AgentState)\n",
    "\n",
    "    def simple_act_on_current_step(state: AgentState) -> AgentState:\n",
    "        \"\"\"Execute the current step WITHOUT tools to avoid message formatting issues\"\"\"\n",
    "        plan = state.get(\"plan\")\n",
    "        if not plan or not plan.steps:\n",
    "            return {\"messages\": [AIMessage(content=\"No steps available. I will answer directly.\")]}\n",
    "        \n",
    "        i = state.get(\"step_index\", 0)\n",
    "        steps = plan.steps\n",
    "        n = len(steps)\n",
    "        \n",
    "        if i >= n:\n",
    "            return {}\n",
    "\n",
    "        current_step = steps[i]\n",
    "        \n",
    "        # Simple execution without tools - just use the LLM to process the step\n",
    "        msgs = [\n",
    "            SystemMessage(content=\"You are a step executor. Execute the given step and provide a clear result. Do NOT use tools.\"),\n",
    "            HumanMessage(content=f\"Execute this step: {current_step}\")\n",
    "        ]\n",
    "        \n",
    "        response = llm.invoke(msgs)  # Use regular LLM without tools\n",
    "        return {\"messages\": [response]}\n",
    "\n",
    "    def simple_advance_or_loop(state: AgentState) -> AgentState:\n",
    "        \"\"\"Simplified advance function\"\"\"\n",
    "        plan = state.get(\"plan\")\n",
    "        if not plan or not plan.steps:\n",
    "            return {}\n",
    "        \n",
    "        i = state.get(\"step_index\", 0)\n",
    "        steps = plan.steps\n",
    "        \n",
    "        if i >= len(steps):\n",
    "            return {}\n",
    "\n",
    "        # Find the last AI message\n",
    "        last_ai_msgs = [m for m in state[\"messages\"][::-1] if isinstance(m, AIMessage)]\n",
    "        if not last_ai_msgs:\n",
    "            return {}\n",
    "        last_ai = last_ai_msgs[0]\n",
    "\n",
    "        # Record the step\n",
    "        step_record = {\n",
    "            \"step_number\": i + 1,\n",
    "            \"step_description\": steps[i],\n",
    "            \"output\": last_ai.content\n",
    "        }\n",
    "\n",
    "        new_results = list(state.get(\"results\", []))\n",
    "        new_results.append(step_record)\n",
    "\n",
    "        return {\n",
    "            \"results\": new_results,\n",
    "            \"step_index\": i + 1\n",
    "        }\n",
    "\n",
    "    def simple_should_continue(state: AgentState) -> str:\n",
    "        plan = state.get(\"plan\")\n",
    "        i = state.get(\"step_index\", 0)\n",
    "        \n",
    "        if not plan or not plan.steps:\n",
    "            return \"finalize\"\n",
    "        if i < len(plan.steps):\n",
    "            return \"act\"\n",
    "        return \"finalize\"\n",
    "\n",
    "    # Nodes - NO TOOLS\n",
    "    workflow.add_node(\"plan\", analyze_and_plan_FIXED)\n",
    "    workflow.add_node(\"act\", simple_act_on_current_step)\n",
    "    workflow.add_node(\"advance\", simple_advance_or_loop)\n",
    "    workflow.add_node(\"finalize\", reflect_and_finalize)\n",
    "\n",
    "    # Simple edges - NO TOOLS\n",
    "    workflow.add_edge(START, \"plan\")\n",
    "    workflow.add_edge(\"plan\", \"act\")\n",
    "    workflow.add_edge(\"act\", \"advance\")  # Always advance after act (no tools)\n",
    "    workflow.add_conditional_edges(\"advance\", simple_should_continue, {\"act\": \"act\", \"finalize\": \"finalize\"})\n",
    "    workflow.add_edge(\"finalize\", END)\n",
    "\n",
    "    return workflow\n",
    "\n",
    "# Build the SIMPLE graph\n",
    "memory_simple = MemorySaver()\n",
    "graph_SIMPLE = create_graph_SIMPLE().compile(checkpointer=memory_simple)\n",
    "\n",
    "print(\"SIMPLE graph (no tools) compiled successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b96d9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting SIMPLE agent execution (no tools)...\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "SIMPLE EXECUTION COMPLETED SUCCESSFULLY!\n",
      "==================================================\n",
      "\n",
      "--- Plan ---\n",
      "Objectives: Determine the current population of Wheaton, IL.\n",
      "Steps:\n",
      "  1. Research the latest population statistics for Wheaton, IL.\n",
      "  2. Check reliable sources such as the U.S. Census Bureau or local government websites.\n",
      "  3. Verify the data for accuracy and recency.\n",
      "Clarifying questions: Are you looking for the most recent population estimate or a specific year?; Do you need additional demographic information along with the population count?\n",
      "Assumptions: Population data is available and up-to-date from reliable sources.; The user is interested in the total population, not demographic breakdowns.\n",
      "Success criteria: The current population number of Wheaton, IL is provided to the user.\n",
      "\n",
      "--- Step Results ---\n",
      "1. Research the latest population statistics for Wheaton, IL.\n",
      "   Output: As of the latest available data, the population of Wheaton, IL, is approximately 53,000 residents. This figure is based on estimates from the U.S. Census Bureau and may vary slightly with new data releases. For the most accurate and current statistics, it is advisable to check the U.S. Census Bureau's website or local government resources.\n",
      "2. Check reliable sources such as the U.S. Census Bureau or local government websites.\n",
      "   Output: I cannot access external websites or databases to check reliable sources like the U.S. Census Bureau or local government websites. However, I can provide information based on my training data up to October 2023. If you have specific questions or need information on a particular topic, feel free to ask!\n",
      "3. Verify the data for accuracy and recency.\n",
      "   Output: I cannot verify data for accuracy and recency as I do not have access to external databases or the ability to check real-time information. My training only includes knowledge up to October 2023. If you have specific data you would like me to help analyze or discuss, please provide it, and I can assist based on the information I have.\n",
      "\n",
      "--- Final Answer ---\n",
      "The current population of Wheaton, IL, is approximately 53,000 residents, based on the latest estimates from the U.S. Census Bureau.\n"
     ]
    }
   ],
   "source": [
    "# Test the SIMPLE version (no tools)\n",
    "user_task = input(\"Enter your task:\\n> \").strip()\n",
    "initial_state: AgentState = {\n",
    "    \"messages\": [\n",
    "        SystemMessage(content=(\n",
    "            \"You are a helpful assistant. Think step-by-step privately, \"\n",
    "            \"but only share a short plan and the final results. Do not reveal your chain-of-thought.\"\n",
    "        )),\n",
    "        HumanMessage(content=user_task),\n",
    "    ],\n",
    "    \"plan\": None,\n",
    "    \"step_index\": 0,\n",
    "    \"results\": [],\n",
    "    \"final_answer\": None\n",
    "}\n",
    "\n",
    "# Test the simple version\n",
    "config = {\n",
    "    \"configurable\": {\"thread_id\": \"simple-thread-1\"},\n",
    "    \"recursion_limit\": 50\n",
    "}\n",
    "\n",
    "print(\"Starting SIMPLE agent execution (no tools)...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "    result = graph_SIMPLE.invoke(initial_state, config)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"SIMPLE EXECUTION COMPLETED SUCCESSFULLY!\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    print(\"\\n--- Plan ---\")\n",
    "    if result.get(\"plan\"):\n",
    "        plan = result[\"plan\"]\n",
    "        print(\"Objectives:\", \"; \".join(plan.objectives or []))\n",
    "        print(\"Steps:\")\n",
    "        for idx, s in enumerate(plan.steps or []):\n",
    "            print(f\"  {idx+1}. {s}\")\n",
    "        if plan.clarifying_questions:\n",
    "            print(\"Clarifying questions:\", \"; \".join(plan.clarifying_questions))\n",
    "        if plan.assumptions:\n",
    "            print(\"Assumptions:\", \"; \".join(plan.assumptions))\n",
    "        if plan.success_criteria:\n",
    "            print(\"Success criteria:\", \"; \".join(plan.success_criteria))\n",
    "\n",
    "    print(\"\\n--- Step Results ---\")\n",
    "    for r in result.get(\"results\", []):\n",
    "        print(f\"{r['step_number']}. {r['step_description']}\")\n",
    "        print(f\"   Output: {r['output']}\")\n",
    "\n",
    "    print(\"\\n--- Final Answer ---\")\n",
    "    print(result.get(\"final_answer\") or \"(No final answer produced)\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nERROR OCCURRED: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dcfe1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fb41c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
